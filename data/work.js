const items = [
  {
    jobTitle: 'Data Engineer Intern',
    company: 'Netflix',
    companyUrl: 'https://www.netflix.com',
    companyLogo: '/static/images/Netflix.png',
    startDate: '2025-05-19',
    endDate: '2025-08-06',
    location: 'Los Gatos, California',
    description: [
      'Incoming Data Engineering Intern at Netflix, working on scalable data pipelines and product analytics within the Studio Data Science & Engineering team.',
      'Focus areas: building robust batch/streaming pipelines, optimizing data transformations, and supporting experimentation platforms at scale.',
      'Technologies: Spark · Python · Airflow · Netflix Metaflow · Trino · AWS',
    ],
  },
  {
    jobTitle: 'Data Engineer Co-op',
    company: 'Glassdoor',
    companyUrl: 'https://glassdoor.com',
    companyLogo: '/static/images/Glassdoor.png',
    startDate: '2024-08-01',
    endDate: '2024-12-31',
    location: 'San Francisco, California',
    description: [
      'Spearheaded the migration of the AppsFlyer data pipeline from API-based extraction to a Snowflake-based solution, slashing data latency by 95% and saving $1.1M in operational costs.',
      'Designed and implemented Airflow DAGs for transferring 10TB+ data from Snowflake to Hive, achieving 99.7% data accuracy and a 40% boost in processing speed.',
      'Integrated Apache Iceberg to optimize storage and improve query execution times by 35%.',
      'Built cost-monitoring dashboards in Snowflake reducing monthly spend by 18%.',
      'Automated SLA monitoring with Slack/PagerDuty alerts, reducing SLA violations by 60%.',
      'Skills: Snowflake · Airflow · Kafka · Hive · Apache Iceberg · Slack · PagerDuty',
    ],
  },
  {
    jobTitle: 'Data Engineer Intern',
    company: 'Glassdoor',
    companyUrl: 'https://glassdoor.com',
    companyLogo: '/static/images/Glassdoor.png',
    startDate: '2024-06-01',
    endDate: '2024-08-01',
    location: 'San Francisco, California',
    description: [
      'Developed the POC for AppsFlyer data migration to Snowflake, enabling full-scale implementation.',
      'Configured Confluent Kafka clusters to mirror production-staging environments, improving replication by 30%.',
      'Built Kafka streaming pipelines to ingest data from S3 to Snowflake, and applied real-time transformations using KSQL Streams.',
      'Implemented real-time error handling and monitoring mechanisms to ensure 99% data consistency.',
      'Skills: Apache Kafka · Confluent · Snowflake · KSQL · S3',
    ],
  },
  {
    jobTitle: 'Data Engineering Research Assistant',
    company: 'San Francisco State University',
    companyLogo: '/static/images/SFSU.png',
    companyUrl: 'https://www.sfsu.edu/index.html',
    startDate: '2023-09-06',
    endDate: '2024-03-15',
    location: 'San Francisco, California',
    description: [
      'Migrated Python ML models to Spark, improving computation speed by 40%.',
      'Automated Algolia search index creation, achieving sub-100ms search response time.',
      'Developed OpenAI-powered chatbot trained on FDA drug data, increasing user engagement and safety.',
      'Published internal documentation for chatbot performance tuning and prompt optimization.',
      'Skills: Apache Spark · Python · OpenAI · Algolia · FDA Data',
    ],
  },
  {
    jobTitle: 'Graduate Assistant',
    company: 'San Francisco State University',
    companyLogo: '/static/images/SFSU.png',
    companyUrl: 'https://www.sfsu.edu/index.html',
    startDate: '2023-09-25',
    endDate: '2024-05-30',
    location: 'San Francisco, California',
    description: [
      'Streamlined survey data collection pipeline in the School of Nursing using Python and Excel.',
      'Enhanced data quality by 30% and reduced analysis preparation time by half.',
      'Created automated dashboards for institutional decision-making.',
      'Skills: Qualtrics · Microsoft Excel · Python · Survey Analysis',
    ],
  },
  {
    jobTitle: 'Data Engineer',
    company: 'Accenture Strategy & Consulting',
    companyUrl: 'https://www.accenture.com/us-en/about/consulting-index',
    companyLogo: '/static/images/Accenture.png',
    startDate: '2022-07-01',
    endDate: '2023-07-21',
    location: 'Gujarat, India',
    description: [
      'Led migration of 39 AWS-backed Tableau dashboards to GCP, improving performance by 30% and cutting costs by 25%.',
      'Developed Python scripts for RDS and Redshift schema migrations, reducing DB update time by 98.33%.',
      'Created an LLM-powered drag-and-drop interface to auto-generate Apache Airflow DAGs using natural language.',
      'Deployed scalable DAG management solutions using Helm and Kubernetes across MWAA and GCP Composer.',
      'Mentored 3 junior engineers and onboarded them to the team’s data orchestration framework.',
      'Skills: GCP · AWS · RDS · Redshift · Airflow · Kubernetes · Python · Helm · Apache Spark · SQL',
    ],
  },
  {
    jobTitle: 'Data Engineer Intern',
    company: 'Accenture Strategy & Consulting',
    companyUrl: 'https://www.accenture.com/us-en/about/consulting-index',
    companyLogo: '/static/images/Accenture.png',
    startDate: '2022-01-07',
    endDate: '2022-06-21',
    location: 'Gujarat, India',
    description: [
      'Built encryption and hashing modules using Scala and Apache Spark to improve data security for an enterprise ETL platform.',
      'Developed AWS Lambda functions integrated with SNS for automating migration workflows.',
      'Improved ETL pipeline reliability and adherence to KPIs by automating data validation.',
      'Skills: Scala · Apache Spark · AWS Lambda · SNS · Data Security · ETL Automation',
    ],
  },
  {
    jobTitle: 'Data Engineer Intern',
    company: 'Zee5',
    companyUrl: 'https://hops.healthcare/',
    companyLogo: '/static/images/Zee5.png',
    startDate: '2021-03-01',
    endDate: '2021-06-30',
    location: 'Gujarat, India',
    description: [
      'Developed a real-time ingestion pipeline using Kafka and Flink for fraud detection across 10M+ daily transactions.',
      'Launched Django web app for secure healthcare report storage, improving access latency by 40%.',
      'Built a custom Spark optimizer to adjust shuffle partitions, improving ETL performance by 35%.',
      'Engineered a BioBERT + Regex-based parsing bot for extracting structured data from clinical reports.',
      'Skills: Apache Kafka · Apache Flink · Spark · BioBERT · Django · MongoDB · Python · NLP',
    ],
  },
]

export default items